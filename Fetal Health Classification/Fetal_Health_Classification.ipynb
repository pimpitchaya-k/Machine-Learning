{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8ilXeWdMj7yc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FVIDtK3ikrHa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('fetal_health.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "XsTSbwGcdz2R",
        "outputId": "db201d6c-f329-4043-a987-7a1af5735ea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-89b9e01b-8a70-4b06-83dd-ed7c825ebb65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline_value</th>\n",
              "      <th>accelerations</th>\n",
              "      <th>fetal_movement</th>\n",
              "      <th>uterine_contractions</th>\n",
              "      <th>light_decelerations</th>\n",
              "      <th>severe_decelerations</th>\n",
              "      <th>prolongued_decelerations</th>\n",
              "      <th>abnormal_short_term_variability</th>\n",
              "      <th>mean_value_of_short_term_variability</th>\n",
              "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
              "      <th>mean_value_of_long_term_variability</th>\n",
              "      <th>histogram_width</th>\n",
              "      <th>histogram_min</th>\n",
              "      <th>histogram_max</th>\n",
              "      <th>histogram_number_of_peaks</th>\n",
              "      <th>histogram_number_of_zeroes</th>\n",
              "      <th>histogram_mode</th>\n",
              "      <th>histogram_mean</th>\n",
              "      <th>histogram_median</th>\n",
              "      <th>histogram_variance</th>\n",
              "      <th>histogram_tendency</th>\n",
              "      <th>fetal_health</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.00000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>133.303857</td>\n",
              "      <td>0.003178</td>\n",
              "      <td>0.009481</td>\n",
              "      <td>0.004366</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>46.990122</td>\n",
              "      <td>1.332785</td>\n",
              "      <td>9.84666</td>\n",
              "      <td>8.187629</td>\n",
              "      <td>70.445908</td>\n",
              "      <td>93.579492</td>\n",
              "      <td>164.025400</td>\n",
              "      <td>4.068203</td>\n",
              "      <td>0.323612</td>\n",
              "      <td>137.452023</td>\n",
              "      <td>134.610536</td>\n",
              "      <td>138.090310</td>\n",
              "      <td>18.808090</td>\n",
              "      <td>0.320320</td>\n",
              "      <td>1.304327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.840844</td>\n",
              "      <td>0.003866</td>\n",
              "      <td>0.046666</td>\n",
              "      <td>0.002946</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>17.192814</td>\n",
              "      <td>0.883241</td>\n",
              "      <td>18.39688</td>\n",
              "      <td>5.628247</td>\n",
              "      <td>38.955693</td>\n",
              "      <td>29.560212</td>\n",
              "      <td>17.944183</td>\n",
              "      <td>2.949386</td>\n",
              "      <td>0.706059</td>\n",
              "      <td>16.381289</td>\n",
              "      <td>15.593596</td>\n",
              "      <td>14.466589</td>\n",
              "      <td>28.977636</td>\n",
              "      <td>0.610829</td>\n",
              "      <td>0.614377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>106.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>125.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>133.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>67.500000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>11.00000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>145.000000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>160.000000</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.481000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>91.00000</td>\n",
              "      <td>50.700000</td>\n",
              "      <td>180.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>182.000000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>269.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89b9e01b-8a70-4b06-83dd-ed7c825ebb65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89b9e01b-8a70-4b06-83dd-ed7c825ebb65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89b9e01b-8a70-4b06-83dd-ed7c825ebb65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       baseline_value  accelerations  ...  histogram_tendency  fetal_health\n",
              "count     2126.000000    2126.000000  ...         2126.000000   2126.000000\n",
              "mean       133.303857       0.003178  ...            0.320320      1.304327\n",
              "std          9.840844       0.003866  ...            0.610829      0.614377\n",
              "min        106.000000       0.000000  ...           -1.000000      1.000000\n",
              "25%        126.000000       0.000000  ...            0.000000      1.000000\n",
              "50%        133.000000       0.002000  ...            0.000000      1.000000\n",
              "75%        140.000000       0.006000  ...            1.000000      1.000000\n",
              "max        160.000000       0.019000  ...            1.000000      3.000000\n",
              "\n",
              "[8 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "eQBTqk5xdlIR",
        "outputId": "ff98777b-ed80-4cf8-d6be-4d7b53f36be8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-81883245-6f47-4ca1-b01a-dea417cd9c7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline_value</th>\n",
              "      <th>accelerations</th>\n",
              "      <th>fetal_movement</th>\n",
              "      <th>uterine_contractions</th>\n",
              "      <th>light_decelerations</th>\n",
              "      <th>severe_decelerations</th>\n",
              "      <th>prolongued_decelerations</th>\n",
              "      <th>abnormal_short_term_variability</th>\n",
              "      <th>mean_value_of_short_term_variability</th>\n",
              "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
              "      <th>mean_value_of_long_term_variability</th>\n",
              "      <th>histogram_width</th>\n",
              "      <th>histogram_min</th>\n",
              "      <th>histogram_max</th>\n",
              "      <th>histogram_number_of_peaks</th>\n",
              "      <th>histogram_number_of_zeroes</th>\n",
              "      <th>histogram_mode</th>\n",
              "      <th>histogram_mean</th>\n",
              "      <th>histogram_median</th>\n",
              "      <th>histogram_variance</th>\n",
              "      <th>histogram_tendency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73</td>\n",
              "      <td>0.5</td>\n",
              "      <td>43</td>\n",
              "      <td>2.4</td>\n",
              "      <td>64</td>\n",
              "      <td>62</td>\n",
              "      <td>126</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>137</td>\n",
              "      <td>121</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>132</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.4</td>\n",
              "      <td>130</td>\n",
              "      <td>68</td>\n",
              "      <td>198</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>136</td>\n",
              "      <td>140</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.1</td>\n",
              "      <td>0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>130</td>\n",
              "      <td>68</td>\n",
              "      <td>198</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>141</td>\n",
              "      <td>135</td>\n",
              "      <td>138</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>117</td>\n",
              "      <td>53</td>\n",
              "      <td>170</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>134</td>\n",
              "      <td>137</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>132</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>19.9</td>\n",
              "      <td>117</td>\n",
              "      <td>53</td>\n",
              "      <td>170</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>136</td>\n",
              "      <td>138</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81883245-6f47-4ca1-b01a-dea417cd9c7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81883245-6f47-4ca1-b01a-dea417cd9c7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81883245-6f47-4ca1-b01a-dea417cd9c7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   baseline_value  accelerations  ...  histogram_variance  histogram_tendency\n",
              "0             120          0.000  ...                  73                   1\n",
              "1             132          0.006  ...                  12                   0\n",
              "2             133          0.003  ...                  13                   0\n",
              "3             134          0.003  ...                  13                   1\n",
              "4             132          0.007  ...                  11                   1\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x = df.iloc[:, 0:21]\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VtLUhbFjgVYM"
      },
      "outputs": [],
      "source": [
        "# Using mean normalization to normalize data.\n",
        "col_to_norm = ['baseline_value', 'abnormal_short_term_variability', 'mean_value_of_short_term_variability',\n",
        "           'percentage_of_time_with_abnormal_long_term_variability','mean_value_of_long_term_variability',\n",
        "           'histogram_width','histogram_min','histogram_max','histogram_number_of_peaks','histogram_mode',\n",
        "           'histogram_mean','histogram_median','histogram_variance']\n",
        "x[col_to_norm] = x[col_to_norm].apply(lambda x : (x-x.mean()) / x.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "5WQl1fHhh8-y",
        "outputId": "0e8c5f63-26c1-430c-9b45-2d5d3173c6a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4d5a0804-5b8d-4a97-98ad-8f5dd10d5be6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline_value</th>\n",
              "      <th>abnormal_short_term_variability</th>\n",
              "      <th>mean_value_of_short_term_variability</th>\n",
              "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
              "      <th>mean_value_of_long_term_variability</th>\n",
              "      <th>histogram_width</th>\n",
              "      <th>histogram_min</th>\n",
              "      <th>histogram_max</th>\n",
              "      <th>histogram_number_of_peaks</th>\n",
              "      <th>histogram_mode</th>\n",
              "      <th>histogram_mean</th>\n",
              "      <th>histogram_median</th>\n",
              "      <th>histogram_variance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.113461e-15</td>\n",
              "      <td>-4.773019e-17</td>\n",
              "      <td>-1.146569e-15</td>\n",
              "      <td>-2.634665e-15</td>\n",
              "      <td>2.902873e-15</td>\n",
              "      <td>-1.941063e-16</td>\n",
              "      <td>-1.485694e-16</td>\n",
              "      <td>-1.162183e-16</td>\n",
              "      <td>-4.292584e-16</td>\n",
              "      <td>-3.797005e-16</td>\n",
              "      <td>-4.836207e-16</td>\n",
              "      <td>2.863811e-16</td>\n",
              "      <td>7.557454e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.774544e+00</td>\n",
              "      <td>-2.035160e+00</td>\n",
              "      <td>-1.282531e+00</td>\n",
              "      <td>-5.352354e-01</td>\n",
              "      <td>-1.454739e+00</td>\n",
              "      <td>-1.731349e+00</td>\n",
              "      <td>-1.474262e+00</td>\n",
              "      <td>-2.342007e+00</td>\n",
              "      <td>-1.379339e+00</td>\n",
              "      <td>-4.728079e+00</td>\n",
              "      <td>-3.951015e+00</td>\n",
              "      <td>-4.222855e+00</td>\n",
              "      <td>-6.490554e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.421982e-01</td>\n",
              "      <td>-8.718830e-01</td>\n",
              "      <td>-7.164345e-01</td>\n",
              "      <td>-5.352354e-01</td>\n",
              "      <td>-6.374329e-01</td>\n",
              "      <td>-8.585628e-01</td>\n",
              "      <td>-8.991645e-01</td>\n",
              "      <td>-6.701559e-01</td>\n",
              "      <td>-7.012319e-01</td>\n",
              "      <td>-5.159559e-01</td>\n",
              "      <td>-6.163130e-01</td>\n",
              "      <td>-6.283659e-01</td>\n",
              "      <td>-5.800366e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.087713e-02</td>\n",
              "      <td>1.169022e-01</td>\n",
              "      <td>-1.503378e-01</td>\n",
              "      <td>-5.352354e-01</td>\n",
              "      <td>-1.399422e-01</td>\n",
              "      <td>-7.562201e-02</td>\n",
              "      <td>-1.960378e-02</td>\n",
              "      <td>-1.128722e-01</td>\n",
              "      <td>-3.621782e-01</td>\n",
              "      <td>9.449668e-02</td>\n",
              "      <td>8.910477e-02</td>\n",
              "      <td>6.288210e-02</td>\n",
              "      <td>-4.074898e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.804440e-01</td>\n",
              "      <td>8.148682e-01</td>\n",
              "      <td>4.157589e-01</td>\n",
              "      <td>6.269213e-02</td>\n",
              "      <td>4.641536e-01</td>\n",
              "      <td>7.586591e-01</td>\n",
              "      <td>8.937861e-01</td>\n",
              "      <td>5.558682e-01</td>\n",
              "      <td>6.549828e-01</td>\n",
              "      <td>6.439040e-01</td>\n",
              "      <td>6.662648e-01</td>\n",
              "      <td>6.850053e-01</td>\n",
              "      <td>1.791695e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.712790e+00</td>\n",
              "      <td>2.327128e+00</td>\n",
              "      <td>6.416384e+00</td>\n",
              "      <td>4.411256e+00</td>\n",
              "      <td>7.553395e+00</td>\n",
              "      <td>2.812274e+00</td>\n",
              "      <td>2.213127e+00</td>\n",
              "      <td>4.122484e+00</td>\n",
              "      <td>4.723627e+00</td>\n",
              "      <td>3.024669e+00</td>\n",
              "      <td>3.039034e+00</td>\n",
              "      <td>3.311748e+00</td>\n",
              "      <td>8.633966e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d5a0804-5b8d-4a97-98ad-8f5dd10d5be6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d5a0804-5b8d-4a97-98ad-8f5dd10d5be6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d5a0804-5b8d-4a97-98ad-8f5dd10d5be6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       baseline_value  ...  histogram_variance\n",
              "count    2.126000e+03  ...        2.126000e+03\n",
              "mean     1.113461e-15  ...        7.557454e-16\n",
              "std      1.000000e+00  ...        1.000000e+00\n",
              "min     -2.774544e+00  ...       -6.490554e-01\n",
              "25%     -7.421982e-01  ...       -5.800366e-01\n",
              "50%     -3.087713e-02  ...       -4.074898e-01\n",
              "75%      6.804440e-01  ...        1.791695e-01\n",
              "max      2.712790e+00  ...        8.633966e+00\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x[col_to_norm].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "BIy0CoYTjI9P",
        "outputId": "070fc154-c948-42f5-d740-32e237132ea8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-428231e2-fbc4-4aac-bc20-5b0ee54f4ae4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>baseline_value</th>\n",
              "      <th>accelerations</th>\n",
              "      <th>fetal_movement</th>\n",
              "      <th>uterine_contractions</th>\n",
              "      <th>light_decelerations</th>\n",
              "      <th>severe_decelerations</th>\n",
              "      <th>prolongued_decelerations</th>\n",
              "      <th>abnormal_short_term_variability</th>\n",
              "      <th>mean_value_of_short_term_variability</th>\n",
              "      <th>percentage_of_time_with_abnormal_long_term_variability</th>\n",
              "      <th>mean_value_of_long_term_variability</th>\n",
              "      <th>histogram_width</th>\n",
              "      <th>histogram_min</th>\n",
              "      <th>histogram_max</th>\n",
              "      <th>histogram_number_of_peaks</th>\n",
              "      <th>histogram_number_of_zeroes</th>\n",
              "      <th>histogram_mode</th>\n",
              "      <th>histogram_mean</th>\n",
              "      <th>histogram_median</th>\n",
              "      <th>histogram_variance</th>\n",
              "      <th>histogram_tendency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2126.000000</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2.126000e+03</td>\n",
              "      <td>2126.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.113461e-15</td>\n",
              "      <td>0.003178</td>\n",
              "      <td>0.009481</td>\n",
              "      <td>0.004366</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000159</td>\n",
              "      <td>-4.773019e-17</td>\n",
              "      <td>-1.146569e-15</td>\n",
              "      <td>-2.634665e-15</td>\n",
              "      <td>2.902873e-15</td>\n",
              "      <td>-1.941063e-16</td>\n",
              "      <td>-1.485694e-16</td>\n",
              "      <td>-1.162183e-16</td>\n",
              "      <td>-4.292584e-16</td>\n",
              "      <td>0.323612</td>\n",
              "      <td>-3.797005e-16</td>\n",
              "      <td>-4.836207e-16</td>\n",
              "      <td>2.863811e-16</td>\n",
              "      <td>7.557454e-16</td>\n",
              "      <td>0.320320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.003866</td>\n",
              "      <td>0.046666</td>\n",
              "      <td>0.002946</td>\n",
              "      <td>0.002960</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.706059</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.610829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.774544e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.035160e+00</td>\n",
              "      <td>-1.282531e+00</td>\n",
              "      <td>-5.352354e-01</td>\n",
              "      <td>-1.454739e+00</td>\n",
              "      <td>-1.731349e+00</td>\n",
              "      <td>-1.474262e+00</td>\n",
              "      <td>-2.342007e+00</td>\n",
              "      <td>-1.379339e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.728079e+00</td>\n",
              "      <td>-3.951015e+00</td>\n",
              "      <td>-4.222855e+00</td>\n",
              "      <td>-6.490554e-01</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.421982e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-8.718830e-01</td>\n",
              "      <td>-7.164345e-01</td>\n",
              "      <td>-5.352354e-01</td>\n",
              "      <td>-6.374329e-01</td>\n",
              "      <td>-8.585628e-01</td>\n",
              "      <td>-8.991645e-01</td>\n",
              "      <td>-6.701559e-01</td>\n",
              "      <td>-7.012319e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.159559e-01</td>\n",
              "      <td>-6.163130e-01</td>\n",
              "      <td>-6.283659e-01</td>\n",
              "      <td>-5.800366e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-3.087713e-02</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.169022e-01</td>\n",
              "      <td>-1.503378e-01</td>\n",
              "      <td>-5.352354e-01</td>\n",
              "      <td>-1.399422e-01</td>\n",
              "      <td>-7.562201e-02</td>\n",
              "      <td>-1.960378e-02</td>\n",
              "      <td>-1.128722e-01</td>\n",
              "      <td>-3.621782e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.449668e-02</td>\n",
              "      <td>8.910477e-02</td>\n",
              "      <td>6.288210e-02</td>\n",
              "      <td>-4.074898e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.804440e-01</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.007000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.148682e-01</td>\n",
              "      <td>4.157589e-01</td>\n",
              "      <td>6.269213e-02</td>\n",
              "      <td>4.641536e-01</td>\n",
              "      <td>7.586591e-01</td>\n",
              "      <td>8.937861e-01</td>\n",
              "      <td>5.558682e-01</td>\n",
              "      <td>6.549828e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.439040e-01</td>\n",
              "      <td>6.662648e-01</td>\n",
              "      <td>6.850053e-01</td>\n",
              "      <td>1.791695e-01</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.712790e+00</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.481000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.015000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>2.327128e+00</td>\n",
              "      <td>6.416384e+00</td>\n",
              "      <td>4.411256e+00</td>\n",
              "      <td>7.553395e+00</td>\n",
              "      <td>2.812274e+00</td>\n",
              "      <td>2.213127e+00</td>\n",
              "      <td>4.122484e+00</td>\n",
              "      <td>4.723627e+00</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.024669e+00</td>\n",
              "      <td>3.039034e+00</td>\n",
              "      <td>3.311748e+00</td>\n",
              "      <td>8.633966e+00</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-428231e2-fbc4-4aac-bc20-5b0ee54f4ae4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-428231e2-fbc4-4aac-bc20-5b0ee54f4ae4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-428231e2-fbc4-4aac-bc20-5b0ee54f4ae4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       baseline_value  accelerations  ...  histogram_variance  histogram_tendency\n",
              "count    2.126000e+03    2126.000000  ...        2.126000e+03         2126.000000\n",
              "mean     1.113461e-15       0.003178  ...        7.557454e-16            0.320320\n",
              "std      1.000000e+00       0.003866  ...        1.000000e+00            0.610829\n",
              "min     -2.774544e+00       0.000000  ...       -6.490554e-01           -1.000000\n",
              "25%     -7.421982e-01       0.000000  ...       -5.800366e-01            0.000000\n",
              "50%     -3.087713e-02       0.002000  ...       -4.074898e-01            0.000000\n",
              "75%      6.804440e-01       0.006000  ...        1.791695e-01            1.000000\n",
              "max      2.712790e+00       0.019000  ...        8.633966e+00            1.000000\n",
              "\n",
              "[8 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LqILGNgQhXKa"
      },
      "outputs": [],
      "source": [
        "x = x.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0BXS6N0Pfs5p",
        "outputId": "70bcb457-ba91-4702-a47d-813f948711f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1a5f456d-e68b-4d6a-888f-cf735ae01866\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fetal_health</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2121</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2122</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2123</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2124</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2125</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2126 rows  1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a5f456d-e68b-4d6a-888f-cf735ae01866')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a5f456d-e68b-4d6a-888f-cf735ae01866 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a5f456d-e68b-4d6a-888f-cf735ae01866');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      fetal_health\n",
              "0                2\n",
              "1                1\n",
              "2                1\n",
              "3                1\n",
              "4                1\n",
              "...            ...\n",
              "2121             2\n",
              "2122             2\n",
              "2123             2\n",
              "2124             2\n",
              "2125             1\n",
              "\n",
              "[2126 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y = df[['fetal_health']]\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jMfgiCnklHKp"
      },
      "outputs": [],
      "source": [
        "y_dummies = pd.get_dummies(y, columns=['fetal_health'])\n",
        "y = y_dummies\n",
        "y=y.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gGpO2bVOnXYl"
      },
      "outputs": [],
      "source": [
        "x_train, x_, y_train, y_ = train_test_split(x, y, test_size=0.2, random_state = 42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UjWC0hPPn0VE"
      },
      "outputs": [],
      "source": [
        "x_val, x_test, y_val, y_test = train_test_split(x_, y_, test_size=0.5, random_state = 42, stratify=y_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9Ge-09BxoAbS"
      },
      "outputs": [],
      "source": [
        "input_layer = layers.Input(shape=(21,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6xQ_y1eeTF7-"
      },
      "outputs": [],
      "source": [
        "lambda_L = 1e-5\n",
        "hidden_layer = layers.Dense(128, kernel_initializer=keras.initializers.HeNormal() , kernel_regularizer=keras.regularizers.L1(lambda_L))(input_layer)\n",
        "hidden_layer = layers.BatchNormalization()(hidden_layer)\n",
        "hidden_layer = layers.Activation('relu')(hidden_layer)\n",
        "\n",
        "hidden_layer = layers.Dense(128, kernel_initializer=keras.initializers.HeNormal() , kernel_regularizer=keras.regularizers.L1(lambda_L))(hidden_layer)\n",
        "hidden_layer = layers.BatchNormalization()(hidden_layer)\n",
        "hidden_layer = layers.Activation('relu')(hidden_layer)\n",
        "\n",
        "hidden_layer = layers.Dense(128, kernel_initializer=keras.initializers.HeNormal() , kernel_regularizer=keras.regularizers.L1(lambda_L))(hidden_layer)\n",
        "hidden_layer = layers.BatchNormalization()(hidden_layer)\n",
        "hidden_layer = layers.Activation('relu')(hidden_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HJ2VYC08oS-I"
      },
      "outputs": [],
      "source": [
        "output_layer = layers.Dense(3, activation='softmax')(hidden_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "F3z-9-LRonxR"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=input_layer, outputs=output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uoGRJywtkcX",
        "outputId": "bbc28b6c-40eb-4c62-aabe-38f378f8312d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 21)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               2816      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,763\n",
            "Trainable params: 36,995\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o2OpbUYMtvGo",
        "outputId": "2e9470fb-1aa0-482d-c9ba-d9abea1abc82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0gN8kjpBpkGA"
      },
      "outputs": [],
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vQagznlPpjOV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=7e-4), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uK16y16spAJ",
        "outputId": "7abb08ef-e315-409d-ad9e-7bfe771139ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.5873 - categorical_accuracy: 0.2206 - val_loss: 1.8003 - val_categorical_accuracy: 0.1502\n",
            "Epoch 2/1500\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.4211 - categorical_accuracy: 0.2494 - val_loss: 1.7509 - val_categorical_accuracy: 0.1362\n",
            "Epoch 3/1500\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 1.2745 - categorical_accuracy: 0.3029 - val_loss: 1.7134 - val_categorical_accuracy: 0.1362\n",
            "Epoch 4/1500\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.1480 - categorical_accuracy: 0.3606 - val_loss: 1.6874 - val_categorical_accuracy: 0.1221\n",
            "Epoch 5/1500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 1.0410 - categorical_accuracy: 0.4665 - val_loss: 1.6712 - val_categorical_accuracy: 0.1080\n",
            "Epoch 6/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.9508 - categorical_accuracy: 0.5535 - val_loss: 1.6622 - val_categorical_accuracy: 0.1268\n",
            "Epoch 7/1500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.8748 - categorical_accuracy: 0.6300 - val_loss: 1.6590 - val_categorical_accuracy: 0.1315\n",
            "Epoch 8/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.8101 - categorical_accuracy: 0.6935 - val_loss: 1.6582 - val_categorical_accuracy: 0.1315\n",
            "Epoch 9/1500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.7549 - categorical_accuracy: 0.7553 - val_loss: 1.6583 - val_categorical_accuracy: 0.1408\n",
            "Epoch 10/1500\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.7073 - categorical_accuracy: 0.7876 - val_loss: 1.6580 - val_categorical_accuracy: 0.1455\n",
            "Epoch 11/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6659 - categorical_accuracy: 0.8100 - val_loss: 1.6569 - val_categorical_accuracy: 0.1549\n",
            "Epoch 12/1500\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6297 - categorical_accuracy: 0.8224 - val_loss: 1.6538 - val_categorical_accuracy: 0.1737\n",
            "Epoch 13/1500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5977 - categorical_accuracy: 0.8329 - val_loss: 1.6478 - val_categorical_accuracy: 0.1972\n",
            "Epoch 14/1500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5693 - categorical_accuracy: 0.8429 - val_loss: 1.6391 - val_categorical_accuracy: 0.2113\n",
            "Epoch 15/1500\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.5437 - categorical_accuracy: 0.8494 - val_loss: 1.6272 - val_categorical_accuracy: 0.2160\n",
            "Epoch 16/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.5205 - categorical_accuracy: 0.8529 - val_loss: 1.6116 - val_categorical_accuracy: 0.2254\n",
            "Epoch 17/1500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4994 - categorical_accuracy: 0.8571 - val_loss: 1.5925 - val_categorical_accuracy: 0.2441\n",
            "Epoch 18/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.4800 - categorical_accuracy: 0.8624 - val_loss: 1.5700 - val_categorical_accuracy: 0.2394\n",
            "Epoch 19/1500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.4620 - categorical_accuracy: 0.8682 - val_loss: 1.5445 - val_categorical_accuracy: 0.2535\n",
            "Epoch 20/1500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4454 - categorical_accuracy: 0.8700 - val_loss: 1.5166 - val_categorical_accuracy: 0.2629\n",
            "Epoch 21/1500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.4299 - categorical_accuracy: 0.8735 - val_loss: 1.4867 - val_categorical_accuracy: 0.2770\n",
            "Epoch 22/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4156 - categorical_accuracy: 0.8771 - val_loss: 1.4553 - val_categorical_accuracy: 0.3005\n",
            "Epoch 23/1500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.4024 - categorical_accuracy: 0.8829 - val_loss: 1.4231 - val_categorical_accuracy: 0.3286\n",
            "Epoch 24/1500\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3902 - categorical_accuracy: 0.8871 - val_loss: 1.3908 - val_categorical_accuracy: 0.3380\n",
            "Epoch 25/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.3790 - categorical_accuracy: 0.8912 - val_loss: 1.3586 - val_categorical_accuracy: 0.3709\n",
            "Epoch 26/1500\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.3686 - categorical_accuracy: 0.8976 - val_loss: 1.3273 - val_categorical_accuracy: 0.3803\n",
            "Epoch 27/1500\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.3591 - categorical_accuracy: 0.9006 - val_loss: 1.2974 - val_categorical_accuracy: 0.4178\n",
            "Epoch 28/1500\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.3505 - categorical_accuracy: 0.9029 - val_loss: 1.2689 - val_categorical_accuracy: 0.4460\n",
            "Epoch 29/1500\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.3425 - categorical_accuracy: 0.9053 - val_loss: 1.2425 - val_categorical_accuracy: 0.4554\n",
            "Epoch 30/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.3351 - categorical_accuracy: 0.9076 - val_loss: 1.2183 - val_categorical_accuracy: 0.4648\n",
            "Epoch 31/1500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.3283 - categorical_accuracy: 0.9076 - val_loss: 1.1965 - val_categorical_accuracy: 0.4883\n",
            "Epoch 32/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.3219 - categorical_accuracy: 0.9082 - val_loss: 1.1772 - val_categorical_accuracy: 0.4883\n",
            "Epoch 33/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.3159 - categorical_accuracy: 0.9076 - val_loss: 1.1602 - val_categorical_accuracy: 0.5023\n",
            "Epoch 34/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3103 - categorical_accuracy: 0.9106 - val_loss: 1.1452 - val_categorical_accuracy: 0.5211\n",
            "Epoch 35/1500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3050 - categorical_accuracy: 0.9129 - val_loss: 1.1322 - val_categorical_accuracy: 0.5258\n",
            "Epoch 36/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2999 - categorical_accuracy: 0.9182 - val_loss: 1.1209 - val_categorical_accuracy: 0.5305\n",
            "Epoch 37/1500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.2950 - categorical_accuracy: 0.9200 - val_loss: 1.1111 - val_categorical_accuracy: 0.5305\n",
            "Epoch 38/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.2904 - categorical_accuracy: 0.9247 - val_loss: 1.1024 - val_categorical_accuracy: 0.5399\n",
            "Epoch 39/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2860 - categorical_accuracy: 0.9235 - val_loss: 1.0945 - val_categorical_accuracy: 0.5634\n",
            "Epoch 40/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2818 - categorical_accuracy: 0.9253 - val_loss: 1.0870 - val_categorical_accuracy: 0.5681\n",
            "Epoch 41/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2777 - categorical_accuracy: 0.9259 - val_loss: 1.0796 - val_categorical_accuracy: 0.5822\n",
            "Epoch 42/1500\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.2739 - categorical_accuracy: 0.9259 - val_loss: 1.0722 - val_categorical_accuracy: 0.5915\n",
            "Epoch 43/1500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.2703 - categorical_accuracy: 0.9271 - val_loss: 1.0645 - val_categorical_accuracy: 0.5962\n",
            "Epoch 44/1500\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.2668 - categorical_accuracy: 0.9288 - val_loss: 1.0564 - val_categorical_accuracy: 0.6056\n",
            "Epoch 45/1500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.2635 - categorical_accuracy: 0.9294 - val_loss: 1.0477 - val_categorical_accuracy: 0.6009\n",
            "Epoch 46/1500\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.2603 - categorical_accuracy: 0.9312 - val_loss: 1.0385 - val_categorical_accuracy: 0.6056\n",
            "Epoch 47/1500\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.2573 - categorical_accuracy: 0.9329 - val_loss: 1.0288 - val_categorical_accuracy: 0.6103\n",
            "Epoch 48/1500\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.2543 - categorical_accuracy: 0.9341 - val_loss: 1.0186 - val_categorical_accuracy: 0.6150\n",
            "Epoch 49/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.2515 - categorical_accuracy: 0.9365 - val_loss: 1.0078 - val_categorical_accuracy: 0.6291\n",
            "Epoch 50/1500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.2487 - categorical_accuracy: 0.9376 - val_loss: 0.9967 - val_categorical_accuracy: 0.6385\n",
            "Epoch 51/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2460 - categorical_accuracy: 0.9388 - val_loss: 0.9853 - val_categorical_accuracy: 0.6432\n",
            "Epoch 52/1500\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.2434 - categorical_accuracy: 0.9400 - val_loss: 0.9736 - val_categorical_accuracy: 0.6385\n",
            "Epoch 53/1500\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.2408 - categorical_accuracy: 0.9412 - val_loss: 0.9618 - val_categorical_accuracy: 0.6479\n",
            "Epoch 54/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.2383 - categorical_accuracy: 0.9418 - val_loss: 0.9500 - val_categorical_accuracy: 0.6432\n",
            "Epoch 55/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.2358 - categorical_accuracy: 0.9412 - val_loss: 0.9383 - val_categorical_accuracy: 0.6526\n",
            "Epoch 56/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.2334 - categorical_accuracy: 0.9429 - val_loss: 0.9269 - val_categorical_accuracy: 0.6667\n",
            "Epoch 57/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.2311 - categorical_accuracy: 0.9429 - val_loss: 0.9157 - val_categorical_accuracy: 0.6761\n",
            "Epoch 58/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.2288 - categorical_accuracy: 0.9435 - val_loss: 0.9048 - val_categorical_accuracy: 0.6761\n",
            "Epoch 59/1500\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.2266 - categorical_accuracy: 0.9441 - val_loss: 0.8943 - val_categorical_accuracy: 0.6761\n",
            "Epoch 60/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.2244 - categorical_accuracy: 0.9441 - val_loss: 0.8842 - val_categorical_accuracy: 0.6761\n",
            "Epoch 61/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.2223 - categorical_accuracy: 0.9447 - val_loss: 0.8745 - val_categorical_accuracy: 0.6761\n",
            "Epoch 62/1500\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.2202 - categorical_accuracy: 0.9453 - val_loss: 0.8652 - val_categorical_accuracy: 0.6761\n",
            "Epoch 63/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.2182 - categorical_accuracy: 0.9459 - val_loss: 0.8563 - val_categorical_accuracy: 0.6761\n",
            "Epoch 64/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.2162 - categorical_accuracy: 0.9459 - val_loss: 0.8477 - val_categorical_accuracy: 0.6808\n",
            "Epoch 65/1500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.2142 - categorical_accuracy: 0.9471 - val_loss: 0.8395 - val_categorical_accuracy: 0.6808\n",
            "Epoch 66/1500\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.2122 - categorical_accuracy: 0.9476 - val_loss: 0.8314 - val_categorical_accuracy: 0.6854\n",
            "Epoch 67/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.2103 - categorical_accuracy: 0.9482 - val_loss: 0.8235 - val_categorical_accuracy: 0.6854\n",
            "Epoch 68/1500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.2084 - categorical_accuracy: 0.9488 - val_loss: 0.8156 - val_categorical_accuracy: 0.6854\n",
            "Epoch 69/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.2066 - categorical_accuracy: 0.9488 - val_loss: 0.8077 - val_categorical_accuracy: 0.6901\n",
            "Epoch 70/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2047 - categorical_accuracy: 0.9494 - val_loss: 0.7997 - val_categorical_accuracy: 0.6901\n",
            "Epoch 71/1500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2029 - categorical_accuracy: 0.9494 - val_loss: 0.7916 - val_categorical_accuracy: 0.6901\n",
            "Epoch 72/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.2012 - categorical_accuracy: 0.9500 - val_loss: 0.7834 - val_categorical_accuracy: 0.6995\n",
            "Epoch 73/1500\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.1994 - categorical_accuracy: 0.9524 - val_loss: 0.7752 - val_categorical_accuracy: 0.6995\n",
            "Epoch 74/1500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.1977 - categorical_accuracy: 0.9529 - val_loss: 0.7669 - val_categorical_accuracy: 0.7042\n",
            "Epoch 75/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1960 - categorical_accuracy: 0.9529 - val_loss: 0.7587 - val_categorical_accuracy: 0.7089\n",
            "Epoch 76/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.1943 - categorical_accuracy: 0.9547 - val_loss: 0.7505 - val_categorical_accuracy: 0.7183\n",
            "Epoch 77/1500\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.1927 - categorical_accuracy: 0.9553 - val_loss: 0.7425 - val_categorical_accuracy: 0.7277\n",
            "Epoch 78/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1910 - categorical_accuracy: 0.9559 - val_loss: 0.7346 - val_categorical_accuracy: 0.7324\n",
            "Epoch 79/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.1894 - categorical_accuracy: 0.9565 - val_loss: 0.7269 - val_categorical_accuracy: 0.7371\n",
            "Epoch 80/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1878 - categorical_accuracy: 0.9565 - val_loss: 0.7192 - val_categorical_accuracy: 0.7418\n",
            "Epoch 81/1500\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.1863 - categorical_accuracy: 0.9576 - val_loss: 0.7118 - val_categorical_accuracy: 0.7418\n",
            "Epoch 82/1500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.1847 - categorical_accuracy: 0.9576 - val_loss: 0.7044 - val_categorical_accuracy: 0.7512\n",
            "Epoch 83/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1832 - categorical_accuracy: 0.9582 - val_loss: 0.6973 - val_categorical_accuracy: 0.7559\n",
            "Epoch 84/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.1817 - categorical_accuracy: 0.9582 - val_loss: 0.6902 - val_categorical_accuracy: 0.7559\n",
            "Epoch 85/1500\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1802 - categorical_accuracy: 0.9582 - val_loss: 0.6832 - val_categorical_accuracy: 0.7559\n",
            "Epoch 86/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1787 - categorical_accuracy: 0.9582 - val_loss: 0.6762 - val_categorical_accuracy: 0.7559\n",
            "Epoch 87/1500\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.1773 - categorical_accuracy: 0.9588 - val_loss: 0.6692 - val_categorical_accuracy: 0.7559\n",
            "Epoch 88/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1758 - categorical_accuracy: 0.9594 - val_loss: 0.6623 - val_categorical_accuracy: 0.7559\n",
            "Epoch 89/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.1744 - categorical_accuracy: 0.9594 - val_loss: 0.6553 - val_categorical_accuracy: 0.7606\n",
            "Epoch 90/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1730 - categorical_accuracy: 0.9606 - val_loss: 0.6483 - val_categorical_accuracy: 0.7606\n",
            "Epoch 91/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1716 - categorical_accuracy: 0.9606 - val_loss: 0.6413 - val_categorical_accuracy: 0.7606\n",
            "Epoch 92/1500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.1702 - categorical_accuracy: 0.9612 - val_loss: 0.6345 - val_categorical_accuracy: 0.7653\n",
            "Epoch 93/1500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1689 - categorical_accuracy: 0.9612 - val_loss: 0.6277 - val_categorical_accuracy: 0.7653\n",
            "Epoch 94/1500\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.1675 - categorical_accuracy: 0.9618 - val_loss: 0.6211 - val_categorical_accuracy: 0.7653\n",
            "Epoch 95/1500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.1662 - categorical_accuracy: 0.9624 - val_loss: 0.6146 - val_categorical_accuracy: 0.7746\n",
            "Epoch 96/1500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1648 - categorical_accuracy: 0.9635 - val_loss: 0.6084 - val_categorical_accuracy: 0.7793\n",
            "Epoch 97/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1635 - categorical_accuracy: 0.9635 - val_loss: 0.6024 - val_categorical_accuracy: 0.7840\n",
            "Epoch 98/1500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.1622 - categorical_accuracy: 0.9647 - val_loss: 0.5966 - val_categorical_accuracy: 0.7934\n",
            "Epoch 99/1500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1609 - categorical_accuracy: 0.9653 - val_loss: 0.5909 - val_categorical_accuracy: 0.7934\n",
            "Epoch 100/1500\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.1597 - categorical_accuracy: 0.9659 - val_loss: 0.5853 - val_categorical_accuracy: 0.7981\n",
            "Epoch 101/1500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.1584 - categorical_accuracy: 0.9659 - val_loss: 0.5797 - val_categorical_accuracy: 0.8028\n",
            "Epoch 102/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1571 - categorical_accuracy: 0.9665 - val_loss: 0.5742 - val_categorical_accuracy: 0.8075\n",
            "Epoch 103/1500\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.1559 - categorical_accuracy: 0.9676 - val_loss: 0.5688 - val_categorical_accuracy: 0.8075\n",
            "Epoch 104/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1547 - categorical_accuracy: 0.9682 - val_loss: 0.5634 - val_categorical_accuracy: 0.8075\n",
            "Epoch 105/1500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.1535 - categorical_accuracy: 0.9688 - val_loss: 0.5580 - val_categorical_accuracy: 0.8075\n",
            "Epoch 106/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.1523 - categorical_accuracy: 0.9700 - val_loss: 0.5527 - val_categorical_accuracy: 0.8075\n",
            "Epoch 107/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.1511 - categorical_accuracy: 0.9706 - val_loss: 0.5475 - val_categorical_accuracy: 0.8075\n",
            "Epoch 108/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.1500 - categorical_accuracy: 0.9718 - val_loss: 0.5423 - val_categorical_accuracy: 0.8075\n",
            "Epoch 109/1500\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.1488 - categorical_accuracy: 0.9718 - val_loss: 0.5373 - val_categorical_accuracy: 0.8028\n",
            "Epoch 110/1500\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.1477 - categorical_accuracy: 0.9718 - val_loss: 0.5325 - val_categorical_accuracy: 0.7981\n",
            "Epoch 111/1500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.1466 - categorical_accuracy: 0.9718 - val_loss: 0.5279 - val_categorical_accuracy: 0.7981\n",
            "Epoch 112/1500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.1454 - categorical_accuracy: 0.9718 - val_loss: 0.5235 - val_categorical_accuracy: 0.7981\n",
            "Epoch 113/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.1443 - categorical_accuracy: 0.9724 - val_loss: 0.5192 - val_categorical_accuracy: 0.8028\n",
            "Epoch 114/1500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.1432 - categorical_accuracy: 0.9724 - val_loss: 0.5149 - val_categorical_accuracy: 0.8075\n",
            "Epoch 115/1500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.1421 - categorical_accuracy: 0.9729 - val_loss: 0.5107 - val_categorical_accuracy: 0.8075\n",
            "Epoch 116/1500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.1410 - categorical_accuracy: 0.9741 - val_loss: 0.5065 - val_categorical_accuracy: 0.8122\n",
            "Epoch 117/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.1400 - categorical_accuracy: 0.9741 - val_loss: 0.5025 - val_categorical_accuracy: 0.8122\n",
            "Epoch 118/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1389 - categorical_accuracy: 0.9747 - val_loss: 0.4985 - val_categorical_accuracy: 0.8169\n",
            "Epoch 119/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1379 - categorical_accuracy: 0.9747 - val_loss: 0.4947 - val_categorical_accuracy: 0.8169\n",
            "Epoch 120/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1368 - categorical_accuracy: 0.9753 - val_loss: 0.4910 - val_categorical_accuracy: 0.8216\n",
            "Epoch 121/1500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.1358 - categorical_accuracy: 0.9765 - val_loss: 0.4874 - val_categorical_accuracy: 0.8216\n",
            "Epoch 122/1500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.1347 - categorical_accuracy: 0.9771 - val_loss: 0.4838 - val_categorical_accuracy: 0.8216\n",
            "Epoch 123/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.1337 - categorical_accuracy: 0.9771 - val_loss: 0.4803 - val_categorical_accuracy: 0.8263\n",
            "Epoch 124/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.1327 - categorical_accuracy: 0.9771 - val_loss: 0.4770 - val_categorical_accuracy: 0.8263\n",
            "Epoch 125/1500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.1317 - categorical_accuracy: 0.9776 - val_loss: 0.4736 - val_categorical_accuracy: 0.8263\n",
            "Epoch 126/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1307 - categorical_accuracy: 0.9782 - val_loss: 0.4701 - val_categorical_accuracy: 0.8310\n",
            "Epoch 127/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.1297 - categorical_accuracy: 0.9782 - val_loss: 0.4668 - val_categorical_accuracy: 0.8357\n",
            "Epoch 128/1500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.1287 - categorical_accuracy: 0.9782 - val_loss: 0.4637 - val_categorical_accuracy: 0.8404\n",
            "Epoch 129/1500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.1277 - categorical_accuracy: 0.9782 - val_loss: 0.4605 - val_categorical_accuracy: 0.8404\n",
            "Epoch 130/1500\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.1268 - categorical_accuracy: 0.9782 - val_loss: 0.4573 - val_categorical_accuracy: 0.8404\n",
            "Epoch 131/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1258 - categorical_accuracy: 0.9782 - val_loss: 0.4543 - val_categorical_accuracy: 0.8404\n",
            "Epoch 132/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1249 - categorical_accuracy: 0.9788 - val_loss: 0.4513 - val_categorical_accuracy: 0.8404\n",
            "Epoch 133/1500\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.1240 - categorical_accuracy: 0.9794 - val_loss: 0.4483 - val_categorical_accuracy: 0.8404\n",
            "Epoch 134/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1230 - categorical_accuracy: 0.9800 - val_loss: 0.4453 - val_categorical_accuracy: 0.8404\n",
            "Epoch 135/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.1221 - categorical_accuracy: 0.9806 - val_loss: 0.4424 - val_categorical_accuracy: 0.8404\n",
            "Epoch 136/1500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1212 - categorical_accuracy: 0.9806 - val_loss: 0.4396 - val_categorical_accuracy: 0.8451\n",
            "Epoch 137/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1203 - categorical_accuracy: 0.9806 - val_loss: 0.4369 - val_categorical_accuracy: 0.8498\n",
            "Epoch 138/1500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1195 - categorical_accuracy: 0.9806 - val_loss: 0.4342 - val_categorical_accuracy: 0.8498\n",
            "Epoch 139/1500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.1186 - categorical_accuracy: 0.9806 - val_loss: 0.4315 - val_categorical_accuracy: 0.8498\n",
            "Epoch 140/1500\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.1177 - categorical_accuracy: 0.9829 - val_loss: 0.4287 - val_categorical_accuracy: 0.8498\n",
            "Epoch 141/1500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.1168 - categorical_accuracy: 0.9829 - val_loss: 0.4261 - val_categorical_accuracy: 0.8498\n",
            "Epoch 142/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.1160 - categorical_accuracy: 0.9829 - val_loss: 0.4237 - val_categorical_accuracy: 0.8498\n",
            "Epoch 143/1500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.1152 - categorical_accuracy: 0.9847 - val_loss: 0.4212 - val_categorical_accuracy: 0.8498\n",
            "Epoch 144/1500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.1143 - categorical_accuracy: 0.9847 - val_loss: 0.4185 - val_categorical_accuracy: 0.8498\n",
            "Epoch 145/1500\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1135 - categorical_accuracy: 0.9859 - val_loss: 0.4159 - val_categorical_accuracy: 0.8545\n",
            "Epoch 146/1500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.1127 - categorical_accuracy: 0.9859 - val_loss: 0.4134 - val_categorical_accuracy: 0.8545\n",
            "Epoch 147/1500\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1119 - categorical_accuracy: 0.9865 - val_loss: 0.4109 - val_categorical_accuracy: 0.8545\n",
            "Epoch 148/1500\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.1111 - categorical_accuracy: 0.9865 - val_loss: 0.4084 - val_categorical_accuracy: 0.8545\n",
            "Epoch 149/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.1103 - categorical_accuracy: 0.9871 - val_loss: 0.4060 - val_categorical_accuracy: 0.8545\n",
            "Epoch 150/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.1095 - categorical_accuracy: 0.9882 - val_loss: 0.4036 - val_categorical_accuracy: 0.8545\n",
            "Epoch 151/1500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.1087 - categorical_accuracy: 0.9888 - val_loss: 0.4012 - val_categorical_accuracy: 0.8592\n",
            "Epoch 152/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.1080 - categorical_accuracy: 0.9888 - val_loss: 0.3988 - val_categorical_accuracy: 0.8592\n",
            "Epoch 153/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.1072 - categorical_accuracy: 0.9900 - val_loss: 0.3966 - val_categorical_accuracy: 0.8592\n",
            "Epoch 154/1500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1064 - categorical_accuracy: 0.9912 - val_loss: 0.3942 - val_categorical_accuracy: 0.8638\n",
            "Epoch 155/1500\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.1057 - categorical_accuracy: 0.9912 - val_loss: 0.3919 - val_categorical_accuracy: 0.8685\n",
            "Epoch 156/1500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1050 - categorical_accuracy: 0.9912 - val_loss: 0.3896 - val_categorical_accuracy: 0.8732\n",
            "Epoch 157/1500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.1042 - categorical_accuracy: 0.9918 - val_loss: 0.3876 - val_categorical_accuracy: 0.8732\n",
            "Epoch 158/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1035 - categorical_accuracy: 0.9924 - val_loss: 0.3856 - val_categorical_accuracy: 0.8732\n",
            "Epoch 159/1500\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.1028 - categorical_accuracy: 0.9924 - val_loss: 0.3836 - val_categorical_accuracy: 0.8732\n",
            "Epoch 160/1500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.1021 - categorical_accuracy: 0.9924 - val_loss: 0.3817 - val_categorical_accuracy: 0.8732\n",
            "Epoch 161/1500\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1014 - categorical_accuracy: 0.9935 - val_loss: 0.3798 - val_categorical_accuracy: 0.8732\n",
            "Epoch 162/1500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.1007 - categorical_accuracy: 0.9935 - val_loss: 0.3778 - val_categorical_accuracy: 0.8732\n",
            "Epoch 163/1500\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.1000 - categorical_accuracy: 0.9935 - val_loss: 0.3757 - val_categorical_accuracy: 0.8732\n",
            "Epoch 164/1500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0993 - categorical_accuracy: 0.9935 - val_loss: 0.3737 - val_categorical_accuracy: 0.8732\n",
            "Epoch 165/1500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0987 - categorical_accuracy: 0.9935 - val_loss: 0.3717 - val_categorical_accuracy: 0.8732\n",
            "Epoch 166/1500\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0980 - categorical_accuracy: 0.9941 - val_loss: 0.3698 - val_categorical_accuracy: 0.8732\n",
            "Epoch 167/1500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0973 - categorical_accuracy: 0.9941 - val_loss: 0.3681 - val_categorical_accuracy: 0.8732\n",
            "Epoch 168/1500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0967 - categorical_accuracy: 0.9941 - val_loss: 0.3665 - val_categorical_accuracy: 0.8732\n",
            "Epoch 169/1500\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.0960 - categorical_accuracy: 0.9941 - val_loss: 0.3648 - val_categorical_accuracy: 0.8732\n",
            "Epoch 170/1500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0954 - categorical_accuracy: 0.9941 - val_loss: 0.3633 - val_categorical_accuracy: 0.8826\n",
            "Epoch 171/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0947 - categorical_accuracy: 0.9947 - val_loss: 0.3619 - val_categorical_accuracy: 0.8873\n",
            "Epoch 172/1500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0941 - categorical_accuracy: 0.9947 - val_loss: 0.3604 - val_categorical_accuracy: 0.8873\n",
            "Epoch 173/1500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0935 - categorical_accuracy: 0.9959 - val_loss: 0.3590 - val_categorical_accuracy: 0.8920\n",
            "Epoch 174/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0929 - categorical_accuracy: 0.9959 - val_loss: 0.3577 - val_categorical_accuracy: 0.9014\n",
            "Epoch 175/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0922 - categorical_accuracy: 0.9959 - val_loss: 0.3564 - val_categorical_accuracy: 0.9014\n",
            "Epoch 176/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0916 - categorical_accuracy: 0.9959 - val_loss: 0.3551 - val_categorical_accuracy: 0.9014\n",
            "Epoch 177/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0910 - categorical_accuracy: 0.9959 - val_loss: 0.3540 - val_categorical_accuracy: 0.9014\n",
            "Epoch 178/1500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0904 - categorical_accuracy: 0.9959 - val_loss: 0.3529 - val_categorical_accuracy: 0.9014\n",
            "Epoch 179/1500\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0899 - categorical_accuracy: 0.9959 - val_loss: 0.3518 - val_categorical_accuracy: 0.9014\n",
            "Epoch 180/1500\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0893 - categorical_accuracy: 0.9959 - val_loss: 0.3508 - val_categorical_accuracy: 0.9014\n",
            "Epoch 181/1500\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0887 - categorical_accuracy: 0.9965 - val_loss: 0.3500 - val_categorical_accuracy: 0.9014\n",
            "Epoch 182/1500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0881 - categorical_accuracy: 0.9965 - val_loss: 0.3491 - val_categorical_accuracy: 0.9014\n",
            "Epoch 183/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0876 - categorical_accuracy: 0.9965 - val_loss: 0.3482 - val_categorical_accuracy: 0.9014\n",
            "Epoch 184/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0870 - categorical_accuracy: 0.9965 - val_loss: 0.3472 - val_categorical_accuracy: 0.9014\n",
            "Epoch 185/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0865 - categorical_accuracy: 0.9965 - val_loss: 0.3463 - val_categorical_accuracy: 0.9014\n",
            "Epoch 186/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0859 - categorical_accuracy: 0.9965 - val_loss: 0.3453 - val_categorical_accuracy: 0.9061\n",
            "Epoch 187/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0854 - categorical_accuracy: 0.9965 - val_loss: 0.3439 - val_categorical_accuracy: 0.9061\n",
            "Epoch 188/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0849 - categorical_accuracy: 0.9965 - val_loss: 0.3426 - val_categorical_accuracy: 0.9061\n",
            "Epoch 189/1500\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0843 - categorical_accuracy: 0.9965 - val_loss: 0.3418 - val_categorical_accuracy: 0.9061\n",
            "Epoch 190/1500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0838 - categorical_accuracy: 0.9965 - val_loss: 0.3408 - val_categorical_accuracy: 0.9061\n",
            "Epoch 191/1500\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0833 - categorical_accuracy: 0.9965 - val_loss: 0.3398 - val_categorical_accuracy: 0.9061\n",
            "Epoch 192/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0828 - categorical_accuracy: 0.9965 - val_loss: 0.3392 - val_categorical_accuracy: 0.9061\n",
            "Epoch 193/1500\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0823 - categorical_accuracy: 0.9965 - val_loss: 0.3384 - val_categorical_accuracy: 0.9061\n",
            "Epoch 194/1500\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0818 - categorical_accuracy: 0.9965 - val_loss: 0.3375 - val_categorical_accuracy: 0.9061\n",
            "Epoch 195/1500\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0813 - categorical_accuracy: 0.9965 - val_loss: 0.3367 - val_categorical_accuracy: 0.9061\n",
            "Epoch 196/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0808 - categorical_accuracy: 0.9965 - val_loss: 0.3361 - val_categorical_accuracy: 0.9061\n",
            "Epoch 197/1500\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0804 - categorical_accuracy: 0.9971 - val_loss: 0.3352 - val_categorical_accuracy: 0.9061\n",
            "Epoch 198/1500\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.0799 - categorical_accuracy: 0.9971 - val_loss: 0.3341 - val_categorical_accuracy: 0.9061\n",
            "Epoch 199/1500\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0794 - categorical_accuracy: 0.9971 - val_loss: 0.3334 - val_categorical_accuracy: 0.9061\n",
            "Epoch 200/1500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0790 - categorical_accuracy: 0.9971 - val_loss: 0.3328 - val_categorical_accuracy: 0.9061\n",
            "Epoch 201/1500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0785 - categorical_accuracy: 0.9976 - val_loss: 0.3319 - val_categorical_accuracy: 0.9061\n",
            "Epoch 202/1500\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0781 - categorical_accuracy: 0.9971 - val_loss: 0.3314 - val_categorical_accuracy: 0.9061\n",
            "Epoch 203/1500\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0776 - categorical_accuracy: 0.9976 - val_loss: 0.3313 - val_categorical_accuracy: 0.9108\n",
            "Epoch 204/1500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0772 - categorical_accuracy: 0.9976 - val_loss: 0.3307 - val_categorical_accuracy: 0.9108\n",
            "Epoch 205/1500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0768 - categorical_accuracy: 0.9976 - val_loss: 0.3297 - val_categorical_accuracy: 0.9061\n",
            "Epoch 206/1500\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0763 - categorical_accuracy: 0.9976 - val_loss: 0.3293 - val_categorical_accuracy: 0.9108\n",
            "Epoch 207/1500\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0759 - categorical_accuracy: 0.9976 - val_loss: 0.3288 - val_categorical_accuracy: 0.9061\n",
            "Epoch 208/1500\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0755 - categorical_accuracy: 0.9982 - val_loss: 0.3284 - val_categorical_accuracy: 0.9061\n",
            "Epoch 209/1500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0751 - categorical_accuracy: 0.9982 - val_loss: 0.3284 - val_categorical_accuracy: 0.9155\n",
            "Epoch 210/1500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0747 - categorical_accuracy: 0.9982 - val_loss: 0.3281 - val_categorical_accuracy: 0.9155\n",
            "Epoch 211/1500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0743 - categorical_accuracy: 0.9982 - val_loss: 0.3278 - val_categorical_accuracy: 0.9155\n",
            "Epoch 212/1500\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0739 - categorical_accuracy: 0.9982 - val_loss: 0.3277 - val_categorical_accuracy: 0.9155\n",
            "Epoch 213/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0735 - categorical_accuracy: 0.9982 - val_loss: 0.3274 - val_categorical_accuracy: 0.9155\n",
            "Epoch 214/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0732 - categorical_accuracy: 0.9982 - val_loss: 0.3273 - val_categorical_accuracy: 0.9155\n",
            "Epoch 215/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0728 - categorical_accuracy: 0.9982 - val_loss: 0.3272 - val_categorical_accuracy: 0.9155\n",
            "Epoch 216/1500\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0724 - categorical_accuracy: 0.9982 - val_loss: 0.3268 - val_categorical_accuracy: 0.9108\n",
            "Epoch 217/1500\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0721 - categorical_accuracy: 0.9982 - val_loss: 0.3265 - val_categorical_accuracy: 0.9108\n",
            "Epoch 218/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0717 - categorical_accuracy: 0.9982 - val_loss: 0.3263 - val_categorical_accuracy: 0.9108\n",
            "Epoch 219/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0713 - categorical_accuracy: 0.9982 - val_loss: 0.3262 - val_categorical_accuracy: 0.9108\n",
            "Epoch 220/1500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0710 - categorical_accuracy: 0.9982 - val_loss: 0.3258 - val_categorical_accuracy: 0.9108\n",
            "Epoch 221/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0707 - categorical_accuracy: 0.9982 - val_loss: 0.3260 - val_categorical_accuracy: 0.9155\n",
            "Epoch 222/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0703 - categorical_accuracy: 0.9982 - val_loss: 0.3258 - val_categorical_accuracy: 0.9155\n",
            "Epoch 223/1500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0700 - categorical_accuracy: 0.9982 - val_loss: 0.3254 - val_categorical_accuracy: 0.9155\n",
            "Epoch 224/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0697 - categorical_accuracy: 0.9982 - val_loss: 0.3252 - val_categorical_accuracy: 0.9155\n",
            "Epoch 225/1500\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0693 - categorical_accuracy: 0.9982 - val_loss: 0.3254 - val_categorical_accuracy: 0.9155\n",
            "Epoch 226/1500\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0690 - categorical_accuracy: 0.9982 - val_loss: 0.3251 - val_categorical_accuracy: 0.9155\n",
            "Epoch 227/1500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0687 - categorical_accuracy: 0.9982 - val_loss: 0.3251 - val_categorical_accuracy: 0.9108\n",
            "Epoch 228/1500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0684 - categorical_accuracy: 0.9982 - val_loss: 0.3252 - val_categorical_accuracy: 0.9108\n",
            "Epoch 229/1500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0681 - categorical_accuracy: 0.9982 - val_loss: 0.3250 - val_categorical_accuracy: 0.9108\n",
            "Epoch 230/1500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0678 - categorical_accuracy: 0.9982 - val_loss: 0.3249 - val_categorical_accuracy: 0.9108\n",
            "Epoch 231/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0675 - categorical_accuracy: 0.9982 - val_loss: 0.3247 - val_categorical_accuracy: 0.9108\n",
            "Epoch 232/1500\n",
            "1/1 [==============================] - 0s 126ms/step - loss: 0.0672 - categorical_accuracy: 0.9982 - val_loss: 0.3243 - val_categorical_accuracy: 0.9108\n",
            "Epoch 233/1500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0669 - categorical_accuracy: 0.9982 - val_loss: 0.3241 - val_categorical_accuracy: 0.9108\n",
            "Epoch 234/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0666 - categorical_accuracy: 0.9982 - val_loss: 0.3240 - val_categorical_accuracy: 0.9108\n",
            "Epoch 235/1500\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0664 - categorical_accuracy: 0.9982 - val_loss: 0.3239 - val_categorical_accuracy: 0.9108\n",
            "Epoch 236/1500\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0661 - categorical_accuracy: 0.9982 - val_loss: 0.3235 - val_categorical_accuracy: 0.9108\n",
            "Epoch 237/1500\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0658 - categorical_accuracy: 0.9982 - val_loss: 0.3236 - val_categorical_accuracy: 0.9108\n",
            "Epoch 238/1500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0656 - categorical_accuracy: 0.9982 - val_loss: 0.3238 - val_categorical_accuracy: 0.9108\n",
            "Epoch 239/1500\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0653 - categorical_accuracy: 0.9982 - val_loss: 0.3231 - val_categorical_accuracy: 0.9108\n",
            "Epoch 240/1500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0650 - categorical_accuracy: 0.9982 - val_loss: 0.3234 - val_categorical_accuracy: 0.9108\n",
            "Epoch 241/1500\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0648 - categorical_accuracy: 0.9982 - val_loss: 0.3231 - val_categorical_accuracy: 0.9108\n",
            "Epoch 242/1500\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0645 - categorical_accuracy: 0.9982 - val_loss: 0.3232 - val_categorical_accuracy: 0.9108\n",
            "Epoch 243/1500\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0643 - categorical_accuracy: 0.9982 - val_loss: 0.3234 - val_categorical_accuracy: 0.9108\n",
            "Epoch 244/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0640 - categorical_accuracy: 0.9988 - val_loss: 0.3233 - val_categorical_accuracy: 0.9108\n",
            "Epoch 245/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0638 - categorical_accuracy: 0.9988 - val_loss: 0.3236 - val_categorical_accuracy: 0.9108\n",
            "Epoch 246/1500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0635 - categorical_accuracy: 0.9988 - val_loss: 0.3234 - val_categorical_accuracy: 0.9108\n",
            "Epoch 247/1500\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0633 - categorical_accuracy: 0.9988 - val_loss: 0.3234 - val_categorical_accuracy: 0.9108\n",
            "Epoch 248/1500\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0631 - categorical_accuracy: 0.9988 - val_loss: 0.3237 - val_categorical_accuracy: 0.9108\n",
            "Epoch 249/1500\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0628 - categorical_accuracy: 0.9988 - val_loss: 0.3235 - val_categorical_accuracy: 0.9108\n",
            "Epoch 250/1500\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0626 - categorical_accuracy: 0.9988 - val_loss: 0.3237 - val_categorical_accuracy: 0.9108\n",
            "Epoch 251/1500\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0624 - categorical_accuracy: 0.9988 - val_loss: 0.3238 - val_categorical_accuracy: 0.9108\n",
            "Epoch 252/1500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0622 - categorical_accuracy: 0.9988 - val_loss: 0.3235 - val_categorical_accuracy: 0.9108\n",
            "Epoch 253/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0619 - categorical_accuracy: 0.9988 - val_loss: 0.3240 - val_categorical_accuracy: 0.9108\n",
            "Epoch 254/1500\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0617 - categorical_accuracy: 0.9988 - val_loss: 0.3235 - val_categorical_accuracy: 0.9108\n",
            "Epoch 255/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0615 - categorical_accuracy: 0.9988 - val_loss: 0.3236 - val_categorical_accuracy: 0.9108\n",
            "Epoch 256/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0613 - categorical_accuracy: 0.9988 - val_loss: 0.3236 - val_categorical_accuracy: 0.9108\n",
            "Epoch 257/1500\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0611 - categorical_accuracy: 0.9988 - val_loss: 0.3230 - val_categorical_accuracy: 0.9108\n",
            "Epoch 258/1500\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0609 - categorical_accuracy: 0.9988 - val_loss: 0.3238 - val_categorical_accuracy: 0.9108\n",
            "Epoch 259/1500\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0607 - categorical_accuracy: 0.9988 - val_loss: 0.3234 - val_categorical_accuracy: 0.9108\n",
            "Epoch 260/1500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0605 - categorical_accuracy: 0.9988 - val_loss: 0.3238 - val_categorical_accuracy: 0.9108\n",
            "Epoch 261/1500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0603 - categorical_accuracy: 0.9988 - val_loss: 0.3244 - val_categorical_accuracy: 0.9108\n",
            "Epoch 262/1500\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0601 - categorical_accuracy: 0.9988 - val_loss: 0.3238 - val_categorical_accuracy: 0.9108\n",
            "Epoch 263/1500\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0599 - categorical_accuracy: 0.9988 - val_loss: 0.3246 - val_categorical_accuracy: 0.9108\n",
            "Epoch 264/1500\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0597 - categorical_accuracy: 0.9988 - val_loss: 0.3243 - val_categorical_accuracy: 0.9108\n",
            "Epoch 265/1500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0595 - categorical_accuracy: 0.9988 - val_loss: 0.3243 - val_categorical_accuracy: 0.9108\n",
            "Epoch 266/1500\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0593 - categorical_accuracy: 0.9988 - val_loss: 0.3250 - val_categorical_accuracy: 0.9108\n",
            "Epoch 267/1500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0591 - categorical_accuracy: 0.9988 - val_loss: 0.3254 - val_categorical_accuracy: 0.9108\n",
            "Epoch 268/1500\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0590 - categorical_accuracy: 0.9988 - val_loss: 0.3248 - val_categorical_accuracy: 0.9108\n",
            "Epoch 269/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0588 - categorical_accuracy: 0.9988 - val_loss: 0.3259 - val_categorical_accuracy: 0.9108\n",
            "Epoch 270/1500\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0586 - categorical_accuracy: 0.9988 - val_loss: 0.3255 - val_categorical_accuracy: 0.9155\n",
            "Epoch 271/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0584 - categorical_accuracy: 0.9988 - val_loss: 0.3254 - val_categorical_accuracy: 0.9155\n",
            "Epoch 272/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0582 - categorical_accuracy: 0.9988 - val_loss: 0.3261 - val_categorical_accuracy: 0.9155\n",
            "Epoch 273/1500\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0581 - categorical_accuracy: 0.9988 - val_loss: 0.3252 - val_categorical_accuracy: 0.9155\n",
            "Epoch 274/1500\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0579 - categorical_accuracy: 0.9988 - val_loss: 0.3257 - val_categorical_accuracy: 0.9155\n",
            "Epoch 275/1500\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0577 - categorical_accuracy: 0.9988 - val_loss: 0.3265 - val_categorical_accuracy: 0.9155\n",
            "Epoch 276/1500\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0576 - categorical_accuracy: 0.9988 - val_loss: 0.3260 - val_categorical_accuracy: 0.9155\n",
            "Epoch 277/1500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0574 - categorical_accuracy: 0.9988 - val_loss: 0.3266 - val_categorical_accuracy: 0.9155\n",
            "Epoch 278/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0572 - categorical_accuracy: 0.9988 - val_loss: 0.3276 - val_categorical_accuracy: 0.9202\n",
            "Epoch 279/1500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0571 - categorical_accuracy: 0.9988 - val_loss: 0.3271 - val_categorical_accuracy: 0.9202\n",
            "Epoch 280/1500\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0569 - categorical_accuracy: 0.9988 - val_loss: 0.3278 - val_categorical_accuracy: 0.9202\n",
            "Epoch 281/1500\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0567 - categorical_accuracy: 0.9988 - val_loss: 0.3283 - val_categorical_accuracy: 0.9202\n",
            "Epoch 282/1500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0566 - categorical_accuracy: 0.9988 - val_loss: 0.3280 - val_categorical_accuracy: 0.9202\n",
            "Epoch 283/1500\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0564 - categorical_accuracy: 0.9988 - val_loss: 0.3285 - val_categorical_accuracy: 0.9202\n",
            "Epoch 284/1500\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0563 - categorical_accuracy: 0.9988 - val_loss: 0.3282 - val_categorical_accuracy: 0.9202\n",
            "Epoch 285/1500\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0561 - categorical_accuracy: 0.9988 - val_loss: 0.3287 - val_categorical_accuracy: 0.9202\n",
            "Epoch 286/1500\n",
            "1/1 [==============================] - 0s 147ms/step - loss: 0.0560 - categorical_accuracy: 0.9988 - val_loss: 0.3295 - val_categorical_accuracy: 0.9202\n",
            "Epoch 287/1500\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0558 - categorical_accuracy: 0.9988 - val_loss: 0.3285 - val_categorical_accuracy: 0.9202\n",
            "Epoch 288/1500\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0557 - categorical_accuracy: 0.9988 - val_loss: 0.3302 - val_categorical_accuracy: 0.9202\n",
            "Epoch 289/1500\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.0555 - categorical_accuracy: 0.9988 - val_loss: 0.3303 - val_categorical_accuracy: 0.9202\n",
            "Epoch 290/1500\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0554 - categorical_accuracy: 0.9988 - val_loss: 0.3302 - val_categorical_accuracy: 0.9202\n",
            "Epoch 291/1500\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0553 - categorical_accuracy: 0.9988 - val_loss: 0.3313 - val_categorical_accuracy: 0.9202\n",
            "Epoch 292/1500\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0551 - categorical_accuracy: 0.9988 - val_loss: 0.3311 - val_categorical_accuracy: 0.9202\n",
            "Epoch 293/1500\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.0550 - categorical_accuracy: 0.9988 - val_loss: 0.3316 - val_categorical_accuracy: 0.9202\n",
            "Epoch 294/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0548 - categorical_accuracy: 0.9988 - val_loss: 0.3319 - val_categorical_accuracy: 0.9202\n",
            "Epoch 295/1500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0547 - categorical_accuracy: 0.9988 - val_loss: 0.3323 - val_categorical_accuracy: 0.9202\n",
            "Epoch 296/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0546 - categorical_accuracy: 0.9988 - val_loss: 0.3321 - val_categorical_accuracy: 0.9202\n",
            "Epoch 297/1500\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0545 - categorical_accuracy: 0.9988 - val_loss: 0.3324 - val_categorical_accuracy: 0.9202\n",
            "Epoch 298/1500\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.0543 - categorical_accuracy: 0.9988 - val_loss: 0.3325 - val_categorical_accuracy: 0.9202\n",
            "Epoch 299/1500\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0542 - categorical_accuracy: 0.9988 - val_loss: 0.3329 - val_categorical_accuracy: 0.9202\n",
            "Epoch 300/1500\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0541 - categorical_accuracy: 0.9988 - val_loss: 0.3337 - val_categorical_accuracy: 0.9202\n",
            "Epoch 301/1500\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0539 - categorical_accuracy: 0.9988 - val_loss: 0.3334 - val_categorical_accuracy: 0.9202\n",
            "Epoch 302/1500\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0538 - categorical_accuracy: 0.9988 - val_loss: 0.3348 - val_categorical_accuracy: 0.9202\n",
            "Epoch 303/1500\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0537 - categorical_accuracy: 0.9988 - val_loss: 0.3345 - val_categorical_accuracy: 0.9202\n",
            "Epoch 304/1500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0536 - categorical_accuracy: 0.9988 - val_loss: 0.3348 - val_categorical_accuracy: 0.9202\n",
            "Epoch 305/1500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0534 - categorical_accuracy: 0.9988 - val_loss: 0.3353 - val_categorical_accuracy: 0.9202\n",
            "Epoch 306/1500\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0533 - categorical_accuracy: 0.9988 - val_loss: 0.3359 - val_categorical_accuracy: 0.9202\n",
            "Epoch 307/1500\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0532 - categorical_accuracy: 0.9988 - val_loss: 0.3366 - val_categorical_accuracy: 0.9202\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x=x_train, y=y_train, batch_size=1700, epochs=1500, callbacks=[earlystop], validation_data=(x_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "w2G22hJHt-Ug"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5ndxOB_buzPv"
      },
      "outputs": [],
      "source": [
        "model.save_weights('weight.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jUsyW3BUIcSE"
      },
      "outputs": [],
      "source": [
        "y_test_predicted = model.predict(x=x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0FLXBy5RJBYP"
      },
      "outputs": [],
      "source": [
        "y_pred = y_test_predicted.argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test.argmax(axis=1)"
      ],
      "metadata": {
        "id": "NzPKg7LntV8e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6uvHSwmAprlJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdd665c3-9df8-413f-da26-5e5d8b1901d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       166\n",
            "           1       0.96      0.83      0.89        29\n",
            "           2       0.94      0.94      0.94        18\n",
            "\n",
            "    accuracy                           0.96       213\n",
            "   macro avg       0.96      0.92      0.94       213\n",
            "weighted avg       0.96      0.96      0.96       213\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Fetal Health Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}